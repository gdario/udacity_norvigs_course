{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 - Introduction - Language\n",
    "\n",
    "Python has a syntax for statements, expressions, classes and operator overloading (e.g. `x + y` where `x` and `y` are instances of a given class. Here the `+` operator is overloaded). It also contains some mini-languages like string formatting. These are small, highly specialized languages that serve a specific purpose. The overarching idea in this unit is that one can develop a domain-specific language to represent and solve specific problems. To this end, we will describe what a *language* is, what a *grammar* is, the difference between a *compiler* and an *interpreter*, and how to use languages as a design tool.\n",
    "\n",
    "## Regular Expressions\n",
    "\n",
    "REs are an example of a language that can be expressed as strings. For example `'a*b*c*'`. To make sense of inputs like these we need to make sense of what the possible *grammars* are and what are the possible *languages* that those grammars correspond to. Regular Expression operate on strings and use patterns represented by strings, but they can become fairly complicated, have nested structures that make them look more like trees than like strings. In the rest of this unit we will be dealing with an internal representation of REs based on trees that will be different from the one above. The input will still be in the form of strings, but they will be internally represented as trees, and we will be dealing with trees from now on.\n",
    "\n",
    "A **grammar** is a description of a language and a **language** is a set of strings. In our example above, `'a*b*c*` is the description of the grammar and strings like `abc`, `aaabbcc`, `ccccc` form the language associated with such grammar.\n",
    "\n",
    "Representing grammars as strings, like `'a*b*c*` or `'a+b?` is convenient for small expressions, but it can become complex with longer ones. We are going to use a representation that is more **compositional**. We are going to describe an **Application Programming Interface (API)**, (as opposed to the UI), i.e., a series of function calls that can be used to describe the grammar of a RE.\n",
    "\n",
    "In the example above, the grammar is described via a Regular Expression. Python has the `re` module, so we could leverage the functions in that module, but the point of this unit is not to learn how to use REs, but rather how to build a **language processor**.\n",
    "\n",
    "The **API calls** listed below are the building blocks of our language description, i.e., of our grammar.\n",
    "\n",
    "- `lit(s)` is the **literal** of string `s`. `lit('a')` describes the language consisting only of character string `'a'`, i.e., `{'a'}`, and nothing else.\n",
    "- `seq(x, y)` is the **sequence** of x and y. `seq(lit('a'), lit('b'))` would describe the language consisting only of the string `'ab'`, i.e. `{'ab'}`. **Question**: is it a *concatentaion*?\n",
    "- `alt(x, y)` stands for **alternatives**. `seq(lit('a'), lit('b'))` would correspond of two possibilities: either `a` or `b`, i.e., `{'a', 'b'}`.\n",
    "- `star(x)` means **zero or more repetitions** of `'x'`, and would therefore correspond to `{'a', 'aa', 'aaa',...}` and so on.\n",
    "- `oneof(s)` is the same as `alt(c1, c2, ...)` where `'c1'. 'c2', ...` etc. are the characters string `s` is made of. `oneof('abc')` matches `{'a', 'b', 'c'}`.\n",
    "- `eol` means **end of line* matches only the end of a character string and nothing else, so it matches the empty string `{''}`, but only at the end. `seq(lit('a'), eol)` matches `{'a'}` if it is at the end of the line.\n",
    "- `dot` matches any possible character `{'a', 'b', 'c',...}`\n",
    "- `plus(s)` means **one or more repetitions** of `'x'`. **NOTE** it does not seem to be implemented in this unit.\n",
    "\n",
    "The API calls above implement a subset of regular expression metacharacters. These are based on [Rob Pike's regular expression matcher](https://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html). The operators above define patterns that are searched fo by these two functions:\n",
    "\n",
    "- `search(pattern, text)`: returns a string that is the earliest match of the pattern in the text, and if there is more than one match in the same location, it will be the longest of those.\n",
    "- `match(pattern, text)`: matches only if the pattern occurs at the very start of `text`, so `match('def', 'abcdef')` would return `None`.\n",
    "\n",
    "The naming of these functions is different from that used by Pike, but is consistent with the naming used in the `re` module. Below we provide the implementations of `search()` and `match()`, plus a couple of utility functions. Of particular interest is the structure of `match_star(p, pattern, text)`, which uses a clever recursive call.\n",
    "\n",
    "`match1(p, text)` function returns `True` if the first character of `text` is `p` *or* if is `p` is `.`, i.e., if the first character is supposed to be *any* character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match1(p, text):\n",
    "    \"\"\"Return True if first character of text matches pattern character p.\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    return p == '.' or p == text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`search(pattern, text)` returns `True` if `pattern` is found anywhere in `text`. If the first character of `pattern` is `^`, `pattern` must appear at the very beginning of `text`. Note that this function depends on the function `match(pattern, text)` defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(pattern, text):\n",
    "    \"Return True if pattern appears anywhere in text.\"\n",
    "    if pattern.startswith('^'):\n",
    "        return match(pattern[1:], text)\n",
    "    else:\n",
    "        return match('.*' + pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`match(pattern, text)` returns `True` if `pattern` appears at the start of the in the text. It covers the following special cases:\n",
    "\n",
    "- `pattern` is the empty string `''`. It returns `True` (**WHY?**).\n",
    "- `pattern` is `'$'`, i.e., which is true only when the end and the beginning of the string coincide, which only happens for the empty string.\n",
    "- If `pattern` is a multicharacter string and the *second* character is either `'*'` or `'?'`, it splits the pattern into three pieces: the first character `p`, the operator `op`, and the pattern `pat`.\n",
    "  - If `op` is `'*'` it calls `match_star(p, pat, text)`.\n",
    "  - If `op` is `'?'` (zero or one occurrances of the character before) it checks whether `p` matches the first character of `text` and whether `pat` matches the rest of `text`. If this is the case, it returns `True`. If this condition is `False`, it checks whether `pat` matches (all of) `text`.\n",
    "- Finally, if none of the above holds, it makes a recursive call where it checks whether the first character of `pattern` matches the first character of `text` with `match()` and uses (recursively) `match(pattern[1:], test[1:])` to match the rest of the pattern against the rest of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(pattern, text):\n",
    "    \"Return True if pattern appears at the start of text.\"\n",
    "    if pattern == '':\n",
    "        return True\n",
    "    elif pattern == '$':\n",
    "        return (text == '')\n",
    "    elif len(pattern) > 1 and pattern[1] in '*?':\n",
    "        p, op, pat = pattern[0], pattern[1], pattern[2:]\n",
    "        if op == '*':\n",
    "            return match_star(p, pat, text)\n",
    "        elif op == '?':\n",
    "            if match1(p, text) and match(pat, text[1:]):\n",
    "                return True\n",
    "            else:\n",
    "                return match(pat, text)\n",
    "        else:\n",
    "            return (match1(pattern[0], text) and\n",
    "                    match(pattern[1:], text[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`match_star(p, pattern, text)` returns `True` if zero or more instances of `p` are followed by `pattern`. As above, matching an arbitrary number of instances is achieved via a recursive call to `match_star()` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_star(p, pattern, text):\n",
    "    \"\"\"Return True if any number of char p, followed by pattern,\n",
    "    matches text.\"\"\"\n",
    "    return (match(pattern, text) or  # match zero times\n",
    "            (match1(p, text) and     # match exactly one time\n",
    "             match_star(p, pattern, text[1:])))  # Brilliant!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Inventory\n",
    "\n",
    "Let's make a list of the concept we need to consider in this unit:\n",
    "\n",
    "- Patterns.\n",
    "- Texts we want to match the patterns against, and the result of this mathing.\n",
    "\n",
    "This is pretty much it, however, we will also consider the following concepts:\n",
    "\n",
    "- A concept of **partial result**.\n",
    "- A notion of **control over iteration**.\n",
    "\n",
    "To understand why these additional notions are needed, let's consider the following example: our pattern is `'a*b+'` and our text is `'aaab'`. If our pattern is represented in our API as `seq(star('a'), plus(lit('b')))`, the first part, `star('a')` would match the first character, but the second part of the pattern, `'b+'` would not match. Only after matching the first three `'a'`s we finally match a `'b'`. We would then need a mechanism to iterate through all possible substrings matching  the first of the pattern, and this seems quite tricky. A similar situation occurs, if we need to evaluate between alternatives. In such cases we need some form of control over this form of iteration.\n",
    "\n",
    "It turns out (no explanation provided in the lesson) that representing these partial results as a **set of remainders of the text** is a good choice. By *remainder* we mean everything left after matching `pattern`. For example, if `pattern = '^a'` and `text = 'abacus'`, the remainder is `'bacus'`.  The `matchset(pattern, text)` function below returns this set of remainders. For example, `matchset(star(lit(a)), text='aaab')` would then return `set(['aaab', 'aab', 'ab', 'b'])`.\n",
    "\n",
    "To implement `matchset(pattern, text)` we first introduce a utility function `components(pattern)` which breaks a pattern into three parts: the operator `op` and the arguments `x` and `y`, which will be `None` if missing.\n",
    "\n",
    "**Important**: here `pattern` is a *tuple* of the form `(op, x, y)`, for example `('lit', 'abc')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = frozenset()  # Acts as Null\n",
    "\n",
    "def components(pattern):\n",
    "    \"\"\"Return the op, x, and y arguments; x and y are None if missing.\n",
    "    pattern is a tuple (op, x, y) with x, y optional.\"\"\"\n",
    "    x = pattern[1] if len(pattern) > 1 else None\n",
    "    y = pattern[2] if len(pattern) > 2 else None\n",
    "    return pattern[0], x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# User Instructions\n",
    "#\n",
    "# The function, matchset, takes a pattern and a text as input\n",
    "# and returns a set of remainders. For example, if matchset \n",
    "# were called with the pattern star(lit(a)) and the text \n",
    "# 'aaab', matchset would return a set with elements \n",
    "# {'aaab', 'aab', 'ab', 'b'}, since a* can consume none, one, two\n",
    "# or all three of the a's in the text.\n",
    "#\n",
    "# dot:   matches any character.\n",
    "# oneof: matches any of the characters in the string it is \n",
    "#        called with. oneof('abc') will match a or b or c.\n",
    "\n",
    "def matchset(pattern, text):\n",
    "    \"Match pattern at start of text; return a set of remainders of text.\"\n",
    "    op, x, y = components(pattern)\n",
    "    if 'lit' == op:\n",
    "        return set([text[len(x):]]) if text.startswith(x) else null\n",
    "    elif 'seq' == op:\n",
    "        return set(t2 for t1 in matchset(x, text) for t2 in matchset(y, t1))\n",
    "    elif 'alt' == op:\n",
    "        return matchset(x, text) | matchset(y, text)\n",
    "    elif 'dot' == op:\n",
    "        return set([text[1:]])\n",
    "    elif 'oneof' == op:\n",
    "        return set([text[text.find(x)+1:]])\n",
    "    elif 'eol' == op:\n",
    "        return set(['']) if text == '' else null\n",
    "    elif 'star' == op:\n",
    "        return (set([text]) |\n",
    "                set(t2 for t1 in matchset(x, text)\n",
    "                    for t2 in matchset(pattern, t1) if t1 != text))\n",
    "    else:\n",
    "        raise ValueError('unknown pattern: %s' % pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `op == 'alt'` the function returns the result of `matchset(x, text)` or `matchset(y, text)`. This to account for the fact that `x` and `y` may be composite expressions. The result is, therefore, the *union* of these two sets.\n",
    "\n",
    "Let's try to understand the case for `'seq'`. Given `('seq', x, y)`, the expression\n",
    "\n",
    "```python\n",
    "set(t2 for t1 in matchset(x, text) for t2 in matchset(y, t1))\n",
    "```\n",
    "\n",
    "`matchset(x, text)` returns a set the elements of which, indicated by `t1`, become the inputs of `matchset(y, t1)`, which in turn returns a set the elements of which we indicate with `t2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    assert matchset((\"lit\", \"abc\"), \"abcdef\") == set([\"def\"])\n",
    "    assert matchset(\n",
    "        (\"seq\", (\"lit\", \"hi \"), (\"lit\", \"there \")), \"hi there nice to meet you\"\n",
    "    ) == set([\"nice to meet you\"])\n",
    "    assert matchset((\"alt\", (\"lit\", \"dog\"), (\"lit\", \"cat\")), \"dog and cat\") == set(\n",
    "        [\" and cat\"]\n",
    "    )\n",
    "    assert matchset((\"dot\",), \"am i missing something?\") == set(\n",
    "        [\"m i missing something?\"]\n",
    "    )\n",
    "    assert matchset((\"oneof\", \"a\"), \"aabc123\") == set([\"abc123\"])\n",
    "    assert matchset((\"eol\",), \"\") == set([\"\"])\n",
    "    assert matchset((\"eol\",), \"not end of line\") == frozenset([])\n",
    "    assert matchset((\"star\", (\"lit\", \"hey\")), \"heyhey!\") == set(\n",
    "        [\"!\", \"heyhey!\", \"hey!\"]\n",
    "    )\n",
    "    return \"tests pass\"\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Match\n",
    "\n",
    "With this definition of `matchset()` we can implement `search(pattern, text)` and `match(pattern, text)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "#---------------\n",
    "# User Instructions\n",
    "#\n",
    "# Complete the search and match functions. Match should\n",
    "# match a pattern only at the start of the text. Search\n",
    "# should match anywhere in the text.\n",
    "\n",
    "null = frozenset()\n",
    "\n",
    "def search(pattern, text):\n",
    "    \"Match pattern anywhere in text; return longest earliest match or None.\"\n",
    "    for i in range(len(text)):\n",
    "        m = match(pattern, text[i:])\n",
    "        if m:\n",
    "            return m\n",
    "        \n",
    "def match(pattern, text):\n",
    "    \"Match pattern against start of text; return longest match found or None.\"\n",
    "    remainders = matchset(pattern, text)\n",
    "    if remainders:\n",
    "        shortest = min(remainders, key=len)\n",
    "        return text[:text.find(shortest)] if len(text) > 1 else text\n",
    "\n",
    "def test():\n",
    "    assert match(('star', ('lit', 'a')),'aaabcd') == 'aaa'\n",
    "    assert match(('alt', ('lit', 'b'), ('lit', 'c')), 'ab') == None\n",
    "    assert match(('alt', ('lit', 'b'), ('lit', 'a')), 'ab') == 'a'\n",
    "    assert search(('alt', ('lit', 'b'), ('lit', 'c')), 'ab') == 'b'\n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Out The API\n",
    "\n",
    "In the code below we provide the implementations of the various API calls. When we call an operator as a function, say `lit('hello')`, we obtain a tuple containing the name of the operator and, depending on the operator, the arguments or other operator-arguments tuples, e.g., `('lit', 'hello)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def lit(string):\n",
    "    return ('lit', string)\n",
    "\n",
    "def seq(x, y):\n",
    "    return ('seq', x, y)\n",
    "\n",
    "def alt(x, y):\n",
    "    return ('alt', x, y)\n",
    "\n",
    "def star(x):\n",
    "    return ('star', x)\n",
    "\n",
    "def plus(x):\n",
    "    return ('seq', x, ('star', x))\n",
    "\n",
    "def opt(x):\n",
    "    return alt(lit(''), x) #opt(x) means that x is optional\n",
    "\n",
    "def oneof(chars):\n",
    "    return ('oneof', tuple(chars))\n",
    "\n",
    "dot = ('dot',)\n",
    "eol = ('eol',)\n",
    "\n",
    "def test():\n",
    "    assert lit('abc') == ('lit', 'abc')\n",
    "    assert seq(('lit', 'a'), ('lit', 'b')) == ('seq', ('lit', 'a'), ('lit', 'b'))\n",
    "    assert alt(('lit', 'a'), ('lit', 'b')) == ('alt', ('lit', 'a'), ('lit', 'b'))\n",
    "    assert star(('lit', 'a')) == ('star', ('lit', 'a'))\n",
    "    assert plus(('lit', 'c')) == ('seq', ('lit', 'c'), ('star', ('lit', 'c')))\n",
    "    assert opt(('lit', 'x')) == ('alt', ('lit', ''), ('lit', 'x'))\n",
    "    assert oneof('abc') == ('oneof', ('a', 'b', 'c'))\n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling\n",
    "\n",
    "Let's summarize how *interpreters* work. In the case of REs we have *patterns*, e.g., `(a|b)+`, and we have *languages*, i.e., set of strings like `{'a', 'b', 'ab', 'ba', ...}` defined by the pattern, and then we have **interpreters** like `matchset(pattern, text)` which return a set of strings. We say that `matchset` is an interpreter because it takes a pattern as a data structure and operates over that pattern. As we can see from its implementation, it has a big `if-elif-else` statement where it checks what type of operator we have in order to select the next action.\n",
    "\n",
    "There is an inherent inefficiency, in that the pattern is only defined once, but we may want to apply that same pattern to many different texts. Every time we have to go through the sequence of `if-elif-else` in order to figure out what type of operator we have, but we should already know that.\n",
    "\n",
    "There is another type of interpreter, called the **compiler**, which does all this work at once, the very first time the pattern is defined. Whereas an interpreter takes a pattern and a text and operates on those, a compiler has two steps. In the first step there is a compilation function which takes just the pattern and returns a *compiled object*, let's call it `c`. Then the compiled object is executed taking the text as argument: `c(text)`. While in the interpreter all the work is done by the interpreter itself, in our case by `matchset()`, in the case of a compiler some of the work is done during the compilation stage and some happens every time we get a new text.\n",
    "\n",
    "In the case of `lit` our API returns:\n",
    "\n",
    "```python\n",
    "def lit(s):\n",
    "    return ('lit', 's')\n",
    "```\n",
    "\n",
    "We defined `matchset(pattern, text)` such that when the pattern contains `'lit'` we compute the remainders as:\n",
    "\n",
    "```python\n",
    "def matchset(pattern, text):\n",
    "    op, x, y = components(pattern)\n",
    "    # other code\n",
    "    if 'lit' == op:\n",
    "        return set([text[len(x):]]) if text.startswith(x) else null\n",
    "    # other code\n",
    "```\n",
    "\n",
    "Now, as soon as we construct a literal, instead of getting a tuple we will get a *function* that returns the set that `matchset()` would have given us. We can then apply this function to `text`.\n",
    "\n",
    "```python\n",
    "def lit(s):\n",
    "    return lambda text: set([text[len(s):]]) if text.startswith(s) else null\n",
    "```\n",
    "\n",
    "## Lower Level Compilers\n",
    "\n",
    "We can define a pattern, say `pat = lit('a')` which is now a function, not a tuple, which gives us the set of the remainders. In an interpreter we have patterns that describe the strings, i.e. the language. In a compiler we have two sets of descriptions to deal with: a description of what the pattern looks like and a description for what the compiled code looks like. In our case, the compiled code consists of Python functions, which are a good target representation because they are flexible. Compilers for languages like C generate code that is the actual machine instructions for the computer, and this is a complex process. There is an intermediate process that generates code for a Virtual Machine. Java and Python follow this approach. The `dis(code)` function from the `dis` module generates the *bytecode* for the Python virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4           0 RESUME                   0\n",
      "              2 LOAD_GLOBAL              0 (math)\n",
      "             14 LOAD_METHOD              1 (sqrt)\n",
      "             36 LOAD_FAST                0 (x)\n",
      "             38 LOAD_CONST               1 (2)\n",
      "             40 BINARY_OP                8 (**)\n",
      "             44 LOAD_FAST                1 (y)\n",
      "             46 LOAD_CONST               1 (2)\n",
      "             48 BINARY_OP                8 (**)\n",
      "             52 BINARY_OP                0 (+)\n",
      "             56 PRECALL                  1\n",
      "             60 CALL                     1\n",
      "             70 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "import math\n",
    "\n",
    "dis.dis(lambda x, y: math.sqrt(x**2 + y**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we implement the compiled functions for `lit(s)`, `seq(x, y)` and `alt(x, y)`. The point is to remember that each of `x, y` are functions returning a set, therefore the compiler for `alt(x, y)` is the union of `x(text)`, which is a set, and `y(text)`, which is another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passes\n"
     ]
    }
   ],
   "source": [
    "def lit(s):\n",
    "    return lambda text: set([text[len(s):]]) if text.startswith(s) else null\n",
    "\n",
    "def seq(x, y):\n",
    "    return lambda text: set().union(*map(y, x(text)))\n",
    "\n",
    "def alt(x, y):\n",
    "    return lambda text: x(text).union(y(text))\n",
    "        \n",
    "null = frozenset([])\n",
    "\n",
    "def oneof(chars):\n",
    "    return lambda t: set([t[1:]]) if (t and t[0] in chars) else null\n",
    "\n",
    "def star(x): return lambda t: (set([t]) | \n",
    "                               set(t2 for t1 in x(t) if t1 != t\n",
    "                                   for t2 in star(x)(t1)))\n",
    "\n",
    "dot = lambda t: set([t[1:]]) if t else null\n",
    "eol = lambda t: set(['']) if t == '' else null\n",
    "\n",
    "def test():\n",
    "    g = alt(lit('a'), lit('b'))\n",
    "    assert g('abc') == set(['bc'])\n",
    "    return 'test passes'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approach, `match(pattern, text)` can be written as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def match(pattern, text):\n",
    "    \"Match pattern against start of text; return longest match found or None.\"\n",
    "    remainders = pattern(text)\n",
    "    if remainders:\n",
    "        shortest = min(remainders, key=len)\n",
    "        return text[:len(text)-len(shortest)]\n",
    "    \n",
    "def test():\n",
    "    assert match(star(lit('a')), 'aaaaabbbaa') == 'aaaaa'\n",
    "    assert match(lit('hello'), 'hello how are you?') == 'hello'\n",
    "    assert match(lit('x'), 'hello how are you?') == None\n",
    "    assert match(oneof('xyz'), 'x**2 + y**2 = r**2') == 'x'\n",
    "    assert match(oneof('xyz'), '   x is here!') == None\n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizers and Generators\n",
    "\n",
    "What we have done so far is the **recognizer task**. We have a function `match(pattern, text)` which *recognizes* if the prefix of `text` is in the language defined by `pattern`.\n",
    "\n",
    "The **generator task** takes a pattern `pattern` and generates the complete language defined by that pattern. For example, the pattern `(a|b)(a|b)` generates the language `{'aa', 'ab', 'ba', 'bb}`. If the pattern is `a*` the corresponding language is an infinite set. We could use a generator function to generate each element of such language one at a time, but we will instead limit the sizes of the strings we want, and this will always produce finite sets. We will take the compiler's approach, and instead of calling `gen(pat)`, i.e., the generator, as a function, on the pattern, we will have the generator compiled into the pattern. `pat()` will therefore be a function and we will apply it to a set of integers representing the possible range of lengths that we want to retrieve and that will return a set of strings. For example, given `pat = a*`, `pat({1, 2, 3})` should return all strings of length 1, 2, or 3, i.e., `{'a', 'aa', 'aaa'}`. The functions below implement the generators for the various operations.\n",
    "\n",
    "This is the whole compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def lit(s):\n",
    "    return lambda Ns: set([s]) if len(s) in Ns else null\n",
    "\n",
    "def alt(x, y):\n",
    "    return lambda Ns: x(Ns) | y(Ns)\n",
    "\n",
    "def star(x):\n",
    "    return lambda Ns: opt(plus(x))(Ns)\n",
    "\n",
    "def plus(x):\n",
    "    return lambda Ns: genseq(x, star(x), Ns, startx=1) #Tricky\n",
    "\n",
    "def oneof(chars):\n",
    "    return lambda Ns: set(chars) if 1 in Ns else null\n",
    "\n",
    "def seq(x, y):\n",
    "    return lambda Ns: genseq(x, y, Ns)\n",
    "\n",
    "def opt(x):\n",
    "    return alt(epsilon, x)\n",
    "\n",
    "dot = oneof('?')    # You could expand the alphabet to more chars.\n",
    "epsilon = lit('')   # The pattern that matches the empty string.\n",
    "\n",
    "def test():\n",
    "    \n",
    "    f = lit('hello')\n",
    "    assert f(set([1, 2, 3, 4, 5])) == set(['hello'])\n",
    "    assert f(set([1, 2, 3, 4]))    == null \n",
    "    \n",
    "    g = alt(lit('hi'), lit('bye'))\n",
    "    assert g(set([1, 2, 3, 4, 5, 6])) == set(['bye', 'hi'])\n",
    "    assert g(set([1, 3, 5])) == set(['bye'])\n",
    "    \n",
    "    h = oneof('theseletters')\n",
    "    assert h(set([1, 2, 3])) == set(['t', 'h', 'e', 's', 'l', 'r'])\n",
    "    assert h(set([2, 3, 4])) == null\n",
    "    \n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the compiler more efficient. For example, in the definition of `lit(s)` we call `set([s])` every time the output of `lit(s)` is called. This seems wasteful. A better way of writing it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lit(s):\n",
    "    set_s = set([s])  # We create this only once\n",
    "    # Every time we call the function below, we refer to the set_s defined above\n",
    "    return lambda Ns: set_s if len(s) in Ns else null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can pull out the `set(chars)` in the defintion of `oneof(chars)`.\n",
    "\n",
    "We still must define `genseq()`. If we pass two arguments, `x, y` to `seq(x, y)` (not `genseq()`), this returns a function of `Ns`, `fn(Ns)` which returns a set of texts that match. In this respect, `seq(x, y)` is delaying the computation of the output. `geneseq(x, y, Ns)`, instead, immediately calculates the output set. One thing we know about this function is that we will have to call `x(Nx)`, where `Nx` is a set of numbers which we don't yet know, and then we will have to call `y(Ny)`, where `Ny` is a possibly different set of numbers, then we have to concatenate together the results and see if this concatenation is within the allowable set defined by `Ns`. What do we know about `Nx` and `Ny` with respect to `Ns`? `Ns` could be a dense set, say `{0, 1, 2, ..., 10}` or it could be a sparse set, say just `{10}`, but in either case, `Nx + Ny <= 10`, and `Nx` can be anything up to 10. For the `y(Ny)` we have two choices: we could wait for `x(Nx)` to return its results and pass them through `y` or we could do it all at once and then try to combine them together and see if they match up. This is easier because in such case `Ny` could also be any number up to 10 in our example. So, both `Nx` and `Ny` could be anything up to 10 inclusive and if we get some results out, for each of them we add them up and check if they are in `Ns`. A candidate solution for the `geneseq()` function is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genseq(x, y, Ns):\n",
    "    Nss = range(max(Ns) + 1)\n",
    "    return set(m1 + m2\n",
    "               for m1 in x(Nss)\n",
    "               for m2 in y(Nss)\n",
    "               if len(m1 + m2) in Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, however, can give rise to infinite recursions. Where do we use recursion? In two functions:`plus()` and `star()`, but `star()` is defined in terms `plus()`, so we need to fix `plus()` in order to avoid infinite recursion. We are essentially defining `x+` as `xx*`, i.e., `seq(x, (star, x))`. In most cases, this works, but if we define `pat = plus(opt(a))`, `opt(a)` means that we are picking either `a` or the empty string, and as we go through the loop we may pick the empty string an infinite number of times and we are never going to get past the values in the set `Ns`, and we will keep going forever. **TODO**: clarify this mess.\n",
    "\n",
    "This is why we have `startx=1` in `star()`, i.e., we always ask `x` to have a length of at least 1, and this is how we break the recursion. We redefine `geneseq()` as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_gen passes\n"
     ]
    }
   ],
   "source": [
    "def genseq(x, y, Ns, startx=0):\n",
    "    \"Set of matches to xy whose total len is in Ns, with x-match's len in Ns-len(...\"\n",
    "    # Tricky part: x+ is defined as x+ = x x*\n",
    "    # To stop the recursion, the first x must generate at least 1 char,\n",
    "    # and then the recursive x* has that many fewer characters. We use\n",
    "    # startx=1 to say that x must match at least 1 character.\n",
    "    if not Ns:\n",
    "        return null\n",
    "    xmatches = x(set(range(startx, max(Ns) + 1)))\n",
    "    Ns_x = set(len(m) for m in xmatches)\n",
    "    Ns_y = set(n - m for n in Ns for m in Ns_x if n - m >= 0)\n",
    "    ymatches = y(Ns_y)\n",
    "    return set(m1 + m2\n",
    "               for m1 in xmatches for m2 in ymatches\n",
    "               if len(m1 + m2) in Ns)\n",
    "\n",
    "def test_gen():\n",
    "    def N(hi):\n",
    "        return set(range(hi + 1))\n",
    "    a, b, c = map(lit, 'abc')\n",
    "    assert star(oneof('ab'))(N(2)) == set(['', 'a', 'aa', 'ab', 'ba', 'bb', 'b'])\n",
    "    assert (seq(star(a), seq(star(b), star(c)))(set([4])) == set(\n",
    "        ['aaaa', 'aaab', 'aaac', 'aabb', 'aabc', 'aacc', 'abbb', 'abbc',\n",
    "         'abcc', 'accc', 'bbbb', 'bbbc', 'bbcc', 'bccc', 'cccc']))\n",
    "    assert (seq(plus(a), seq(plus(b), plus(c)))(set([5])) == set(\n",
    "        ['aaabc', 'aabbc', 'aabcc', 'abbbc', 'abbcc', 'abccc']))\n",
    "    assert (seq(oneof('bcfhrsm'), lit('at'))(N(3)) == set(\n",
    "        ['bat', 'cat', 'fat', 'hat', 'mat', 'rat', 'sat']))\n",
    "    assert (seq(star(alt(a, b)), opt(c))(set([3])) == set(\n",
    "        ['aaa', 'aab', 'aac', 'aba', 'abb', 'abc', 'baa', 'bab',\n",
    "         'bac', 'bba', 'bbb', 'bbc']))\n",
    "    assert lit('hello')(set([5])) == set(['hello'])\n",
    "    assert lit('hello')(set([4])) == set()\n",
    "    assert lit('hello')(set([6])) == set()\n",
    "    return 'test_gen passes'\n",
    "\n",
    "print(test_gen())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the above we have taken advantage of the *composability* of Python functions. Functions, unlike statements and expressions, which can only be composed by the programmer, can be composed dynamically. Functions also provide *control over time*: we can divide some of the work we want to do such that we do some now and some later. Expressions don't allow this separation.\n",
    "\n",
    "## Changing `seq()`\n",
    "\n",
    "The `seq()` function is binary, in the sense that it takes two arguments. If we want a sequence of four objects, say `a, b, c, d`, we need to call `seq(a, seq(b, seq(c, d)))`. It would be much easier if we could just write `seq(a, b, c, d)`. We want to refactor this function, but aren't we changing it's API? We should ask ourselves:\n",
    "\n",
    "1. Which other functions does `seq()` interact with in our program?\n",
    "2. If I change `seq()`, are these changes *backward compatible*? In other words, do I have to modify also the functions `seq()` interacts with?\n",
    "3. Are the changes *internal* or *external*? Am I changing something inside `seq()` that doesn't affect the callers, or am I changing the interface to the outside world?\n",
    "\n",
    "### Function mapping: decorators\n",
    "\n",
    "We can refactor `seq()` without changing the API. To do this, we need to *map* our binary function `f(x, y)` and convert it to an n-ary function `g(x, y, ...)`. This mapping is done via a function, `n_ary()` in the example below, that takes the binary function `f(x, y)` and returns an n-ary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('myseq', 'a', ('myseq', 'b', 'c'))\n"
     ]
    }
   ],
   "source": [
    "def n_ary(f):\n",
    "    \"\"\"Given binary function f(x, y), return an n_ary function such that\n",
    "    f(x, y, z) = f(x, f(y, z)) etc. Also allow for f(x) = x.\"\"\"\n",
    "    def n_ary_f(x, *args):\n",
    "        return x if not args else f(x, n_ary_f(*args))\n",
    "    return n_ary_f\n",
    "\n",
    "def myseq(x, y):\n",
    "    \"My own seq function (meh)\"\n",
    "    return ('myseq', x, y)\n",
    "\n",
    "myseq = n_ary(myseq)\n",
    "print(myseq('a', 'b', 'c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern above is so common in Python that there is a special notation: the **decorator notation**. We can leverage it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('myseq', 'a', ('myseq', 'b', 'c'))\n"
     ]
    }
   ],
   "source": [
    "@n_ary\n",
    "def myseq(x, y):\n",
    "    \"My own seq function (meh)\"\n",
    "    return ('myseq', x, y)\n",
    "\n",
    "print(myseq('a', 'b', 'c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One limitation, however, is that if we check the docstring of the decorated function, this is what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function n_ary_f in module __main__:\n",
      "\n",
      "n_ary_f(x, *args)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(myseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily `functools` has a function called `update_wrapper()` that takes two functions and copies the name, the documentation plus other things from the old function to the new function. For this, we need to modify the definition of `n_ary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import update_wrapper\n",
    "\n",
    "def n_ary(f):\n",
    "    \"\"\"Given binary function f(x, y), return an n_ary function such that\n",
    "    f(x, y, z) = f(x, f(y, z)) etc. Also allow for f(x) = x.\"\"\"\n",
    "    def n_ary_f(x, *args):\n",
    "        return x if not args else f(x, n_ary_f(*args))\n",
    "    update_wrapper(n_ary_f, f)  # update_wrapper(new_fn, old_fn) \n",
    "    return n_ary_f\n",
    "\n",
    "@n_ary\n",
    "def myseq(x, y):\n",
    "    \"My own seq function (meh)\"\n",
    "    return ('myseq', x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function myseq in module __main__:\n",
      "\n",
      "myseq(x, y)\n",
      "    My own seq function (meh)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(myseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even better approach is to create our own decorator that adds the the `update_wrapper()` call to, in the case above, `n_ary_f()`. We will call this new decorator `@decorator`. If we use `n_ary()` as a decorator on `myseq()` and apply `@decorator` to `n_ary()`, we have two updates to consider: one for the function we want to decorate, and one for the decorator itself. The pattern we want to follow is:\n",
    "\n",
    "```python\n",
    "def decorator(d):  # d is a decorator function\n",
    "    def _d(f):\n",
    "        update_wrapper(d(f), f)\n",
    "    update_wrapper(_d, d)\n",
    "    return _d\n",
    "```\n",
    "\n",
    "With this setup, `n_ary = decorator(n_ary)` would be updated by `update_wrapper(_d, d)` and `myseq = n_ary(myseq)` would be updated by `update_wrapper(d(f), f)`.\n",
    "\n",
    "This is what we ultimately get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(d):\n",
    "    \"Make function d a decorator. d wraps a function f\"\n",
    "    def _d(f):\n",
    "        return update_wrapper(d(f), f)\n",
    "    update_wrapper(_d, d)\n",
    "    return _d\n",
    "\n",
    "@decorator\n",
    "def n_ary(f):\n",
    "    \"\"\"Given bynary function f(x, y) return an n-ary function such that\n",
    "    f(x, y ,z) = f(x, f(y, z)), etc. Also allow for f(x) = x.\"\"\"\n",
    "    def n_ary_f(x, *args):\n",
    "        return x if not args else f(x, n_ary_f(*args))\n",
    "    return n_ary_f\n",
    "\n",
    "@decorator\n",
    "def myseq(x, y):\n",
    "    return ('myseq', x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function myseq in module __main__:\n",
      "\n",
      "myseq(x, y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(myseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more confusingly, the following code also works (due to [Darius Bacon](https://github.com/darius)). **TODO** understand what's going on here. Video 46 - Decorated Decorators Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(d):\n",
    "    \"Make function d a decorator. d wraps a function fn.\"\n",
    "    return lambda fn: update_wrapper(d(fn), fn)\n",
    "\n",
    "decorator = decorator(decorator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Management\n",
    "\n",
    "We want to leverage the concept of **memoization**. Particularly with recursive functions we will be making the same function calls over and over again. If the result of those function calls does not change, and it takes a long time to be computed, it is better to store the input and the relative result in a cache. For example:\n",
    "\n",
    "```python\n",
    "def fib(n):\n",
    "    if n in in cache:\n",
    "        return cache[n]\n",
    "    cache[n] = result = # code to compute the result\n",
    "    return result\n",
    "```\n",
    "\n",
    "However, we may have many functions where we may want to use memoization, and we don't want to rewrite the code above over and over. We can implement this with a decorator, let's call it `@memo`. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@decorator\n",
    "def memo(f):\n",
    "    \"\"\"Decorator that caches the return value for each call to f(args).\n",
    "    Then, when called again with same args, we can just look it up.\"\"\"\n",
    "    cache = {}\n",
    "    def _f(*args):\n",
    "        try:\n",
    "            return cache[args]\n",
    "        except KeyError:\n",
    "            cache[args] = result = f(*args)\n",
    "            return result\n",
    "        except TypeError:\n",
    "            # Some elements of args can't be a dict key\n",
    "            return f(args)\n",
    "    return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have use a `try-except` pattern rather than an `if-else` one. It's like asking for forgiveness (`try-catch`) as opposed to asking for permissiono (`if-else`). In this case we use the `try-except` because we have the second type of exception: `TypeError`, which happens when the argument is not hashable, for example if we use a list as a key. If we used a particularly simple hash function for lists of integers, say the sum of the elements, we may have `y = [1, 2, 3]` which would be associated with the hash value 6. If, however, we modify the list so that `y[0] = 10`, now the hash value is 15.\n",
    "\n",
    "To see how effective our `@memo` decorator is we may compare the decorated version of the function with the original one. We may measure time or, more interestingly, the number of function calls. We did something like this in a previous lesson, but now we will do it with a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@decorator\n",
    "def countcalls(f):\n",
    "    \"Decorator that makes the function count calls to it, in callcounts[f].\"\n",
    "    def _f(*args):\n",
    "        callcounts[_f] +=1\n",
    "        return f(*args)\n",
    "    callcounts[_f] = 0\n",
    "    return _f\n",
    "\n",
    "callcounts = {}\n",
    "\n",
    "@countcalls\n",
    "def fib(n):\n",
    "    return 1 if n <= 1 else fib(n - 1) + fib(n - 2)\n",
    "\n",
    "fib(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@countcalls\n",
    "@memo\n",
    "def fib(n):\n",
    "    return 1 if n <= 1 else fib(n - 1) + fib(n - 2)\n",
    "\n",
    "fib(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** this testing function is currently useless. It already treats the API calls as functions rather as than tuples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search():\n",
    "    a, b, c = lit('a'), lit('b'), lit('c')\n",
    "    abcstars = seq(star(a), seq(star(b), star(c)))\n",
    "    dotstar = star(dot)\n",
    "    assert search(lit('def'), 'abcdefg') == 'def'\n",
    "    assert search(seq('def', eol), 'abcdef') == 'def'\n",
    "    assert search(seq(lit('def'), eol), 'abcdefg') == None\n",
    "    assert search(a, 'not the start') == 'a'\n",
    "    assert match(a, 'not the start') == None\n",
    "    assert match(abcstars, 'aaabbbccccccccdef') == 'aaabbbcccccccc'\n",
    "    assert match(abcstars, 'junk') == ''\n",
    "    assert all(match(seq(abcstars, eol), s) == s for s in 'abc aaabbccc aaaabcccc'.split())\n",
    "    assert all(match(seq(abcstars, eol), s) == None for s in 'cab aaabbcccd aaaa-b-cccc'.split())\n",
    "    r = seq(lit('ab'), seq(dotstar, seq(lit('aca'), seq(dotstar, seq(a, eol)))))\n",
    "    assert all(search(r, s) is not None for s in 'abracadabra abacaa about-acacia-flora'.split())\n",
    "    assert all(match(seq(c, seq(dotstar, b)), s) is not None for s in 'cab cob carob cb carbuncle'.split())\n",
    "    assert not any(match(seq(c, seq(dot, b)), s) for s in 'carb cb across scab'.split())\n",
    "    return 'test_search passes'\n",
    "\n",
    "# print(test_search())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
