{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3 - Introduction - Language\n",
    "\n",
    "Python has a syntax for statements, expressions, classes and operator overloading (e.g. `x + y` where `x` and `y` are instances of a given class. Here the `+` operator is overloaded). It also contains some mini-languages like string formatting. These are small, highly specialized languages that serve a specific purpose. The overarching idea in this unit is that one can develop a domain-specific language to represent and solve specific problems. To this end, we will describe what a *language* is, what a *grammar* is, the difference between a *compiler* and an *interpreter*, and how to use languages as a design tool.\n",
    "\n",
    "## Regular Expressions\n",
    "\n",
    "REs are an example of a language that can be expressed as strings. For example `'a*b*c*'`. To make sense of inputs like these we need to make sense of what the possible *grammars* are and what are the possible *languages* that those grammars correspond to. Regular Expression operate on strings and use patterns represented by strings, but they can become fairly complicated, have nested structures that make them look more like trees than like strings. In the rest of this unit we will be dealing with an internal representation of REs based on trees that will be different from the one above. The input will still be in the form of strings, but they will be internally represented as trees, and we will be dealing with trees from now on.\n",
    "\n",
    "A **grammar** is a description of a language and a **language** is a set of strings. In our example above, `'a*b*c*` is the description of the grammar and strings like `abc`, `aaabbcc`, `ccccc` form the language associated with such grammar.\n",
    "\n",
    "Representing grammars as strings, like `'a*b*c*` or `'a+b?` is convenient for small expressions, but it can become complex with longer ones. We are going to use a representation that is more **compositional**. We are going to describe an **Application Programming Interface (API)**, (as opposed to the UI), i.e., a series of function calls that can be used to describe the grammar of a RE.\n",
    "\n",
    "In the example above, the grammar is described via a Regular Expression. Python has the `re` module, so we could leverage the functions in that module, but the point of this unit is not to learn how to use REs, but rather how to build a **language processor**.\n",
    "\n",
    "The **API calls** listed below are the building blocks of our language description, i.e., of our grammar.\n",
    "\n",
    "- `lit(s)` is the **literal** of string `s`. `lit('a')` describes the language consisting only of character string `'a'`, i.e., `{'a'}`, and nothing else.\n",
    "- `seq(x, y)` is the **sequence** of x and y. `seq(lit('a'), lit('b'))` would describe the language consisting only of the string `'ab'`, i.e. `{'ab'}`. **Question**: is it a *concatentaion*?\n",
    "- `alt(x, y)` stands for **alternatives**. `seq(lit('a'), lit('b'))` would correspond of two possibilities: either `a` or `b`, i.e., `{'a', 'b'}`.\n",
    "- `star(x)` means **zero or more repetitions** of `'x'`, and would therefore correspond to `{'a', 'aa', 'aaa',...}` and so on.\n",
    "- `oneof(s)` is the same as `alt(c1, c2, ...)` where `'c1'. 'c2', ...` etc. are the characters string `s` is made of. `oneof('abc')` matches `{'a', 'b', 'c'}`.\n",
    "- `eol` means **end of line* matches only the end of a character string and nothing else, so it matches the empty string `{''}`, but only at the end. `seq(lit('a'), eol)` matches `{'a'}` if it is at the end of the line.\n",
    "- `dot` matches any possible character `{'a', 'b', 'c',...}`\n",
    "- `plus(s)` means **one or more repetitions** of `'x'`. **NOTE** it does not seem to be implemented in this unit.\n",
    "\n",
    "The API calls above implement a subset of regular expression metacharacters. These are based on [Rob Pike's regular expression matcher](https://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html).\n",
    "\n",
    "Below we create a function to test the implementation of these operators. The will not currently pass, since we have not implemented the API calls. The function below relies on two functions:\n",
    "\n",
    "- `search(pattern, text)`: returns a string that is the earliest match of the pattern in the text, and if there is more than one match in the same location, it will be the longest of those.\n",
    "- `match(pattern, text)`: matches only if the pattern occurs at the very start of `text`, so `match('def', 'abcdef')` would return `None`.\n",
    "\n",
    "Below we provide the implementations of `search()` and `match()`, plus a couple of utility functions. Of particular interest is the structure of `match_star(p, pattern, text)`, which uses a clever recursive call. Since we have not yet implemented the API calls, `test_search()` will not pass.\n",
    "\n",
    "The `match1(p, text)` function returns `True` if the first character of `text` is `p` *or* if is `p` is `.`, i.e., if the first character is supposed to be *any* character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match1(p, text):\n",
    "    \"\"\"Return True if first character of text matches pattern character p.\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    return p == '.' or p == text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`search(pattern, text)` returns `True` if `pattern` is found anywhere in `text`. If the first character of `pattern` is `^`, `pattern` must appear at the very beginning of `text`. Note that this function depends on the function `match(pattern, text)` defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(pattern, text):\n",
    "    \"Return True if pattern appears anywhere in text.\"\n",
    "    if pattern.startswith('^'):\n",
    "        return match(pattern[1:], text)\n",
    "    else:\n",
    "        return match('.*' + pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`match(pattern, text)` returns `True` if `pattern` appears at the start of the in the text. It covers the following special cases:\n",
    "\n",
    "- `pattern` is the empty string `''`. It returns `True` (**WHY?**).\n",
    "- `pattern` is `'$'`, i.e., which is true only when the end and the beginning of the string coincide, which only happens for the empty string.\n",
    "- If `pattern` is a multicharacter string and the *second* character is either `'*'` or `'?'`, it splits the pattern into three pieces: the first character `p`, the operator `op`, and the pattern `pat`.\n",
    "  - If `op` is `'*'` it calls `match_star(p, pat, text)`.\n",
    "  - If `op` is `'?'` it checks whether `p` matches the first character of `text` and whether `pat` matches the rest of `text`. If this is the case, it returns `True`. If this condition is `False`, it applies the case when the first character is not matched, and checks whether `pat` matches (all of) `text`.\n",
    "- Finally, if none of the above holds, it makes a recursive call where it checks whether the first character of `pattern` matches the first character of `text` and uses (recursively) `match(pattern[1:], test[1:])` to match the rest of the pattern against the rest of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(pattern, text):\n",
    "    \"Return True if pattern appears at the start of text.\"\n",
    "    if pattern == '':\n",
    "        return True\n",
    "    elif pattern == '$':\n",
    "        return (text == '')\n",
    "    elif len(pattern) > 1 and pattern[1] in '*?':\n",
    "        p, op, pat = pattern[0], pattern[1], pattern[2:]\n",
    "        if op == '*':\n",
    "            return match_star(p, pat, text)\n",
    "        elif op == '?':\n",
    "            if match1(p, text) and match(pat, text[1:]):\n",
    "                return True\n",
    "            else:\n",
    "                return match(pat, text)\n",
    "        else:\n",
    "            return (match1(pattern[0], text) and\n",
    "                    match(pattern[1:], text[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`match_star(p, pattern, text)` returns `True` if zero or more instances of `p` are followed by `pattern`. As above, matching an arbitrary number of instances is achieved via a recursive call to `match_star()` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_star(p, pattern, text):\n",
    "    \"\"\"Return True if any number of char p, followed by pattern,\n",
    "    matches text.\"\"\"\n",
    "    return (match(pattern, text) or  # match zero times\n",
    "            (match1(p, text) and     # match exactly one time\n",
    "             match_star(p, pattern, text[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Inventory\n",
    "\n",
    "Let's make a list of the concept we need to consider in this unit:\n",
    "\n",
    "- Patterns.\n",
    "- Texts we want to match the patterns against, and the result of this mathing.\n",
    "\n",
    "This is pretty much it, however, we will also consider the following concepts:\n",
    "\n",
    "- A concept of **partial result**.\n",
    "- A notion of **control over iteration**.\n",
    "\n",
    "To understand why these additional notions are needed, let's consider the following example: our pattern is `'a*b+'` and our text is `'aaab'`. If our pattern is represented in our API as `seq(star('a'), plus(lit('b')))`, the first part, `star('a')` would match the first character, but the second part of the pattern, `'b+'` would not match. Only after matching the first three `'a'`s we finally match a `'b'`. We would then need a mechanism to iterate through all possible substrings matching  the first of the pattern, and this seems quite tricky. A similar situation occurs, if we need to evaluate between alternatives. In such cases we need some form of control over this form of iteration.\n",
    "\n",
    "It is difficult to see it now, but if we choose to represent these partial results as a **set of remainders of the text**, where by *remainder* we mean everything left after the match, then everything falls in place, and much of the above trickiness goes away. We are therefore going to introduce a function called `matchset(pattern, text)` that returns this set of remainders. For example `matchset(star(lit(a)), text='aaab')` the output would be the set `{aaab, aab, ab, b}`.\n",
    "\n",
    "To implement `matchset(pattern, text)` we first introduce a utility function `components(pattern)` which breaks a pattern into three parts: the operator `op` and the arguments `x` and `y`, which will be `None` if missing.\n",
    "\n",
    "**Important**: here `pattern` is a *tuple* of the form `(op, x, y)`, for example `('lit', 'abc')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = frozenset()  # Acts as Null\n",
    "\n",
    "def components(pattern):\n",
    "    \"Return the op, x, and y arguments; x and y are None if missing.\"\n",
    "    x = pattern[1] if len(pattern) > 1 else None\n",
    "    y = pattern[2] if len(pattern) > 2 else None\n",
    "    return pattern[0], x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# User Instructions\n",
    "#\n",
    "# The function, matchset, takes a pattern and a text as input\n",
    "# and returns a set of remainders. For example, if matchset \n",
    "# were called with the pattern star(lit(a)) and the text \n",
    "# 'aaab', matchset would return a set with elements \n",
    "# {'aaab', 'aab', 'ab', 'b'}, since a* can consume none, one, two\n",
    "# or all three of the a's in the text.\n",
    "#\n",
    "# dot:   matches any character.\n",
    "# oneof: matches any of the characters in the string it is \n",
    "#        called with. oneof('abc') will match a or b or c.\n",
    "\n",
    "def matchset(pattern, text):\n",
    "    \"Match pattern at start of text; return a set of remainders of text.\"\n",
    "    op, x, y = components(pattern)\n",
    "    if 'lit' == op:\n",
    "        return set([text[len(x):]]) if text.startswith(x) else null\n",
    "    elif 'seq' == op:\n",
    "        return set(t2 for t1 in matchset(x, text) for t2 in matchset(y, t1))\n",
    "    elif 'alt' == op:\n",
    "        return matchset(x, text) | matchset(y, text)\n",
    "    elif 'dot' == op:\n",
    "        return set([text[1:]])\n",
    "    elif 'oneof' == op:\n",
    "        return set([text[text.find(x)+1:]])\n",
    "    elif 'eol' == op:\n",
    "        return set(['']) if text == '' else null\n",
    "    elif 'star' == op:\n",
    "        return (set([text]) |\n",
    "                set(t2 for t1 in matchset(x, text)\n",
    "                    for t2 in matchset(pattern, t1) if t1 != text))\n",
    "    else:\n",
    "        raise ValueError('unknown pattern: %s' % pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `op == 'alt'` the function returns the result of `matchset(x, text)` or `matchset(y, text)`. This to account for the fact that `x` and `y` may be composite expressions. The result is, therefore, the *union* of these two sets.\n",
    "\n",
    "Let's try to understand the case for `'seq'`. Given `('seq', x, y)`, the expression\n",
    "\n",
    "```python\n",
    "set(t2 for t1 in matchset(x, text) for t2 in matchset(y, t1))\n",
    "```\n",
    "\n",
    "applies recursively `matchset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    assert matchset((\"lit\", \"abc\"), \"abcdef\") == set([\"def\"])\n",
    "    assert matchset(\n",
    "        (\"seq\", (\"lit\", \"hi \"), (\"lit\", \"there \")), \"hi there nice to meet you\"\n",
    "    ) == set([\"nice to meet you\"])\n",
    "    assert matchset((\"alt\", (\"lit\", \"dog\"), (\"lit\", \"cat\")), \"dog and cat\") == set(\n",
    "        [\" and cat\"]\n",
    "    )\n",
    "    assert matchset((\"dot\",), \"am i missing something?\") == set(\n",
    "        [\"m i missing something?\"]\n",
    "    )\n",
    "    assert matchset((\"oneof\", \"a\"), \"aabc123\") == set([\"abc123\"])\n",
    "    assert matchset((\"eol\",), \"\") == set([\"\"])\n",
    "    assert matchset((\"eol\",), \"not end of line\") == frozenset([])\n",
    "    assert matchset((\"star\", (\"lit\", \"hey\")), \"heyhey!\") == set(\n",
    "        [\"!\", \"heyhey!\", \"hey!\"]\n",
    "    )\n",
    "    return \"tests pass\"\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Out The API\n",
    "\n",
    "In the code below we provide the implementations of the various API calls. When we call an operator as a function, say `lit('hello')`, we obtain a tuple containing the name of the operator and, depending on the operator, the arguments or other operator-arguments tuples, e.g., `('lit', 'hello)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def lit(string):\n",
    "    return ('lit', string)\n",
    "\n",
    "def seq(x, y):\n",
    "    return ('seq', x, y)\n",
    "\n",
    "def alt(x, y):\n",
    "    return ('alt', x, y)\n",
    "\n",
    "def star(x):\n",
    "    return ('star', x)\n",
    "\n",
    "def plus(x):\n",
    "    return ('seq', x, ('star', x))\n",
    "\n",
    "def opt(x):\n",
    "    return alt(lit(''), x) #opt(x) means that x is optional\n",
    "\n",
    "def oneof(chars):\n",
    "    return ('oneof', tuple(chars))\n",
    "\n",
    "dot = ('dot',)\n",
    "eol = ('eol',)\n",
    "\n",
    "def test():\n",
    "    assert lit('abc') == ('lit', 'abc')\n",
    "    assert seq(('lit', 'a'), ('lit', 'b')) == ('seq', ('lit', 'a'), ('lit', 'b'))\n",
    "    assert alt(('lit', 'a'), ('lit', 'b')) == ('alt', ('lit', 'a'), ('lit', 'b'))\n",
    "    assert star(('lit', 'a')) == ('star', ('lit', 'a'))\n",
    "    assert plus(('lit', 'c')) == ('seq', ('lit', 'c'), ('star', ('lit', 'c')))\n",
    "    assert opt(('lit', 'x')) == ('alt', ('lit', ''), ('lit', 'x'))\n",
    "    assert oneof('abc') == ('oneof', ('a', 'b', 'c'))\n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "#---------------\n",
    "# User Instructions\n",
    "#\n",
    "# Complete the search and match functions. Match should\n",
    "# match a pattern only at the start of the text. Search\n",
    "# should match anywhere in the text.\n",
    "\n",
    "null = frozenset()\n",
    "\n",
    "def search(pattern, text):\n",
    "    \"Match pattern anywhere in text; return longest earliest match or None.\"\n",
    "    for i in range(len(text)):\n",
    "        m = match(pattern, text[i:])\n",
    "        if m:\n",
    "            return m\n",
    "        \n",
    "def match(pattern, text):\n",
    "    \"Match pattern against start of text; return longest match found or None.\"\n",
    "    remainders = matchset(pattern, text)\n",
    "    if remainders:\n",
    "        shortest = min(remainders, key=len)\n",
    "        return text[:text.find(shortest)] if len(text) > 1 else text\n",
    "\n",
    "def test():\n",
    "    assert match(('star', ('lit', 'a')),'aaabcd') == 'aaa'\n",
    "    assert match(('alt', ('lit', 'b'), ('lit', 'c')), 'ab') == None\n",
    "    assert match(('alt', ('lit', 'b'), ('lit', 'a')), 'ab') == 'a'\n",
    "    assert search(('alt', ('lit', 'b'), ('lit', 'c')), 'ab') == 'b'\n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling\n",
    "\n",
    "Let's summarize how *interpreters* work. In the case of REs we have *patterns*, e.g., `(a|b)+`, and we have *languages*, i.e., set of strings like `{'a', 'b', 'ab', 'ba', ...}` defined by the pattern, and then we have **interpreters** like `matchset(pattern, text)` which return a set of strings. We say that `matchset` is an interpreter because it takes a pattern as a data structure and operates over that pattern. As we can see from its implementation, it has a big `if-elif-else` statement where it checks what type of operator we have in order to select the next action.\n",
    "\n",
    "There is an inherent inefficiency, in that the pattern is only defined once, but we may want to apply that same pattern to many different texts. Every time we have to go through the sequence of `if-elif-else` in order to figure out what type of operator we have, but we should already know that.\n",
    "\n",
    "There is another type of interpreter, called the **compiler**, which does all this work at once, the very first time the pattern is defined. Whereas an interpreter takes a pattern and a text and operates on those, a compiler has two steps. In the first step there is a compilation function which takes just the pattern and returns a *compiled object*, let's call it `c`. Then there is the execution of that compiled object where we apply it to the text, i.e., `c(text)` to get the result. While in the interpreter all the work is done by the interpreter itself, in our case by `matchset()`, in the case of a compiler some of the work is done during the compilation stage and some happens every time we get a new text.\n",
    "\n",
    "Let's see how it works with a reduced form of `matchset(pattern, text)` limited to the `lit` case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** this testing function is currently useless. It already treats the API calls as functions rather as than tuples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def litmatchset(pattern, text):\n",
    "    op, x, y = components(pattern)\n",
    "    if 'lit' == op:\n",
    "        return set([text[len(x):]]) if text.startswith(x) else null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to take individual statements like the one above and we are going to put them in various parts of the compiler, and each of those parts are going to live in the constructor for the individual type of pattern. In the case of `lit` we defined\n",
    "\n",
    "```python\n",
    "def lit(s):\n",
    "    return ('lit', 's')\n",
    "```\n",
    "\n",
    "but now we are going to return  a function, and precisely a function that returns line 4 of `litmatchset`. Now, as soon as we construct a literal, instead of getting a tuple we get the function from the text to the result that `matchset()` would have given us. We can then apply this function to `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' string'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lit(s):\n",
    "    return lambda text: set([text[len(s):]]) if text.startswith(s) else null\n",
    "\n",
    "lit('a')('a string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower Level Compilers\n",
    "\n",
    "We can define a pattern, say `pat = lit('a')` which is now a function, not a tuple, which gives us the set of the remainders. In an interpreter we have patterns that describe the strings, i.e. the language. In a compiler we have two sets of descriptions to deal with: a description of what the pattern looks like and a description for what the compiled code looks like. In our case, the compiled code consists of Python functions, which are a good target representation because they are flexible. Compilers for language like C generate code that is the actual machine instructions for the computer, and this is a complex process. There is an intermediate process that generates code for a Virtual Machine. Java and Python follow this approach. The `dis(code)` function from the `dis` module generates the *bytecode* for the Python virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4           0 RESUME                   0\n",
      "              2 LOAD_GLOBAL              0 (math)\n",
      "             14 LOAD_METHOD              1 (sqrt)\n",
      "             36 LOAD_FAST                0 (x)\n",
      "             38 LOAD_CONST               1 (2)\n",
      "             40 BINARY_OP                8 (**)\n",
      "             44 LOAD_FAST                1 (y)\n",
      "             46 LOAD_CONST               1 (2)\n",
      "             48 BINARY_OP                8 (**)\n",
      "             52 BINARY_OP                0 (+)\n",
      "             56 PRECALL                  1\n",
      "             60 CALL                     1\n",
      "             70 RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "import math\n",
    "\n",
    "dis.dis(lambda x, y: math.sqrt(x**2 + y**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we implement the compiled functions for `lit(s)`, `seq(x, y)` and `alt(x, y)`. The point is to remember that each of `x, y` are functions returning a set, therefore the compiler for `alt(x, y)` is the union of `x(text)`, which is a set, and `y(text)`, which is another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passes\n"
     ]
    }
   ],
   "source": [
    "def lit(s):\n",
    "    return lambda text: set([text[len(s):]]) if text.startswith(s) else null\n",
    "\n",
    "def seq(x, y):\n",
    "    return lambda text: set().union(*map(y, x(text)))\n",
    "\n",
    "def alt(x, y):\n",
    "    return lambda text: x(text).union(y(text))\n",
    "        \n",
    "null = frozenset([])\n",
    "\n",
    "def oneof(chars):\n",
    "    return lambda t: set([t[1:]]) if (t and t[0] in chars) else null\n",
    "\n",
    "def star(x): return lambda t: (set([t]) | \n",
    "                               set(t2 for t1 in x(t) if t1 != t\n",
    "                                   for t2 in star(x)(t1)))\n",
    "\n",
    "dot = lambda t: set([t[1:]]) if t else null\n",
    "eol = lambda t: set(['']) if t == '' else null\n",
    "\n",
    "def test():\n",
    "    g = alt(lit('a'), lit('b'))\n",
    "    assert g('abc') == set(['bc'])\n",
    "    return 'test passes'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approach, `match(pattern, text)` can be written as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def match(pattern, text):\n",
    "    \"Match pattern against start of text; return longest match found or None.\"\n",
    "    remainders = pattern(text)# your code here.\n",
    "    if remainders:\n",
    "        shortest = min(remainders, key=len)\n",
    "        return text[:len(text)-len(shortest)]\n",
    "    \n",
    "# null = frozenset([])  # Defined in a cell above\n",
    "\n",
    "def test():\n",
    "    assert match(star(lit('a')), 'aaaaabbbaa') == 'aaaaa'\n",
    "    assert match(lit('hello'), 'hello how are you?') == 'hello'\n",
    "    assert match(lit('x'), 'hello how are you?') == None\n",
    "    assert match(oneof('xyz'), 'x**2 + y**2 = r**2') == 'x'\n",
    "    assert match(oneof('xyz'), '   x is here!') == None\n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizers and Generators\n",
    "\n",
    "What we have done so far is the **recognizer task**. We have a function `match(pattern, text)` which *recognizes* if the prefix of `text` is in the language defined by `pattern`.\n",
    "\n",
    "The **generator task** takes a pattern `pattern` and generates the complete language defined by that pattern. For example, the pattern `(a|b)(a|b)` generates the language `{'aa', 'ab', 'ba', 'bb}`. If the pattern is `a*` the corresponding language is an infinite set. We could use a generator function to generate each element of such language one at a time, but we will instead limit the sizes of the strings we want, and this will always produce finite sets. We will take the compiler's approach, and instead of calling `gen(pat)`, i.e., the generator, as a function, on the pattern, we will have the generator compiled into the pattern. `pat()` will therefore be a function and we will apply it to a set of integers representing the possible range of lengths that we want to retrieve and that will return a set of strings. For example, given `pat = a*`, `pat({1, 2, 3})` should return all strings of length 1, 2, or 3, i.e., `{'a', 'aa', 'aaa'}`. The functions below implement the generators for the various operations.\n",
    "\n",
    "This is the whole compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass\n"
     ]
    }
   ],
   "source": [
    "def lit(s):\n",
    "    return lambda Ns: set([s]) if len(s) in Ns else null\n",
    "\n",
    "def alt(x, y):\n",
    "    return lambda Ns: x(Ns) | y(Ns)\n",
    "\n",
    "def star(x):\n",
    "    return lambda Ns: opt(plus(x))(Ns)\n",
    "\n",
    "def plus(x):\n",
    "    return lambda Ns: genseq(x, star(x), Ns, startx=1) #Tricky\n",
    "\n",
    "def oneof(chars):\n",
    "    return lambda Ns: set(chars) if 1 in Ns else null\n",
    "\n",
    "def seq(x, y):\n",
    "    return lambda Ns: genseq(x, y, Ns)\n",
    "\n",
    "def opt(x):\n",
    "    return alt(epsilon, x)\n",
    "\n",
    "dot = oneof('?')    # You could expand the alphabet to more chars.\n",
    "epsilon = lit('')   # The pattern that matches the empty string.\n",
    "\n",
    "def test():\n",
    "    \n",
    "    f = lit('hello')\n",
    "    assert f(set([1, 2, 3, 4, 5])) == set(['hello'])\n",
    "    assert f(set([1, 2, 3, 4]))    == null \n",
    "    \n",
    "    g = alt(lit('hi'), lit('bye'))\n",
    "    assert g(set([1, 2, 3, 4, 5, 6])) == set(['bye', 'hi'])\n",
    "    assert g(set([1, 3, 5])) == set(['bye'])\n",
    "    \n",
    "    h = oneof('theseletters')\n",
    "    assert h(set([1, 2, 3])) == set(['t', 'h', 'e', 's', 'l', 'r'])\n",
    "    assert h(set([2, 3, 4])) == null\n",
    "    \n",
    "    return 'tests pass'\n",
    "\n",
    "print(test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the compiler more efficient. For example, in the definition of `lit(s)` we call `set([s])` every time the output of `lit(s)` is called. This seems wasteful. A better way of writing it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lit(s):\n",
    "    set_s = set([s])  # We create this only once\n",
    "    # Every time we call the function below, we refer to the set_s defined above\n",
    "    return lambda Ns: set_s if len(s) in Ns else null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can pull out the `set(chars)` in the defintion of `oneof(chars)`.\n",
    "\n",
    "We still must define `genseq()`. If we pass two arguments, `x, y` to `seq(x, y)` (not `genseq()`), this returns a function of `Ns`, `fn(Ns)` which returns a set of texts that match. In this respect, `seq(x, y)` is delaying the computation of the output. `geneseq(x, y, Ns)`, instead, immediately calculates the output set. One thing we know about this function is that we will have to call `x(Nx)`, where `Nx` is a set of numbers which we don't yet know, and then we will have to call `y(Ny)`, where `Ny` is a possibly different set of numbers, then we have to concatenate together the results and see if the concatenation of some `x` and some `y` is within the allowable set defined by `Ns`. What do we konw about `Nx` and `Ny` with respect to `Ns`? `Ns` could be a dense set, say `{0, 1, 2, ..., 10}` or it could be a sparse set, say just `{10}`, but in either case, `Nx + Ny <= 10`, and `Nx` can be anything up to 10, therefore\n",
    "\n",
    "**TO BE CONTINUED** - VIDEO Genseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search():\n",
    "    a, b, c = lit('a'), lit('b'), lit('c')\n",
    "    abcstars = seq(star(a), seq(star(b), star(c)))\n",
    "    dotstar = star(dot)\n",
    "    assert search(lit('def'), 'abcdefg') == 'def'\n",
    "    assert search(seq('def', eol), 'abcdef') == 'def'\n",
    "    assert search(seq(lit('def'), eol), 'abcdefg') == None\n",
    "    assert search(a, 'not the start') == 'a'\n",
    "    assert match(a, 'not the start') == None\n",
    "    assert match(abcstars, 'aaabbbccccccccdef') == 'aaabbbcccccccc'\n",
    "    assert match(abcstars, 'junk') == ''\n",
    "    assert all(match(seq(abcstars, eol), s) == s for s in 'abc aaabbccc aaaabcccc'.split())\n",
    "    assert all(match(seq(abcstars, eol), s) == None for s in 'cab aaabbcccd aaaa-b-cccc'.split())\n",
    "    r = seq(lit('ab'), seq(dotstar, seq(lit('aca'), seq(dotstar, seq(a, eol)))))\n",
    "    assert all(search(r, s) is not None for s in 'abracadabra abacaa about-acacia-flora'.split())\n",
    "    assert all(match(seq(c, seq(dotstar, b)), s) is not None for s in 'cab cob carob cb carbuncle'.split())\n",
    "    assert not any(match(seq(c, seq(dot, b)), s) for s in 'carb cb across scab'.split())\n",
    "    return 'test_search passes'\n",
    "\n",
    "# print(test_search())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
